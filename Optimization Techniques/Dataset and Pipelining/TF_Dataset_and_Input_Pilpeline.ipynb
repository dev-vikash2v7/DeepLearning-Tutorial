{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_no = [ 23 , 54, -1, -89, 100 ,10 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to TF Dataset \n",
    "\n",
    "<b> The tf.data.Dataset API supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern:</b>\n",
    "\n",
    "<li> Create a source dataset from your input data.</li>\n",
    "<li> Apply dataset transformations to preprocess the data.</li>\n",
    "<li>Iterate over the dataset and process the elements.</li>\n",
    "\n",
    "<em>Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory.</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_no)\n",
    "type(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "54\n",
      "-1\n",
      "-89\n",
      "100\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for element in tf_dataset:\n",
    "  print(element.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "54\n",
      "-1\n",
      "-89\n",
      "100\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for element in tf_dataset.as_numpy_iterator():\n",
    "  print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 108, -2, -178, 200, 20]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation\n",
    "tf_dataset = tf_dataset.map(lambda x: x*2)\n",
    "list(tf_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "108\n",
      "-2\n"
     ]
    }
   ],
   "source": [
    "# Take first 3 element\n",
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 108, 200, 20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering Data\n",
    "tf_dataset = tf_dataset.filter(lambda x: x > 0)\n",
    "list(tf_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 108, 200, 20]\n",
      "[108, 20, 46, 200]\n"
     ]
    }
   ],
   "source": [
    "# Randomly rearranging\n",
    "# Filtering Data\n",
    "print(list(tf_dataset.as_numpy_iterator()))\n",
    "tf_dataset = tf_dataset.shuffle(3)\n",
    "print(list(tf_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200  46]\n",
      "[108  20]\n"
     ]
    }
   ],
   "source": [
    "#Batching the data set\n",
    "# tf_dataset = tf_dataset.shuffle(3)\n",
    "# print(list(tf_dataset.as_numpy_iterator()))\n",
    "for sales_batch in tf_dataset.batch(2):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 54, -1, -89, 100, 10]\n"
     ]
    }
   ],
   "source": [
    "daily_sales_no = [ 23 , 54, -1, -89, 100 ,10 ]\n",
    "tf_dataset  = tf.data.Dataset.from_tensor_slices(daily_sales_no)\n",
    "print(list(tf_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 230 1000]\n",
      "[100 540]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset_new = tf_dataset.filter(lambda x : x > 0 ).map(lambda y : y*10).shuffle(3).batch(2)\n",
    "for sales in tf_dataset_new:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = tf.data.Dataset.list_files('Flower Dataset/*/*'  , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Flower Dataset\\\\daisy\\\\100080576_f52e8ee070_n_jpg.rf.77fc70826524be2700a7465c39dd2663.jpg'\n",
      "b'Flower Dataset\\\\daisy\\\\10140303196_b88d3d6cec_jpg.rf.2f4f52a5d9739ed87bd185a3af4904ed.jpg'\n",
      "b'Flower Dataset\\\\daisy\\\\10172379554_b296050f82_n_jpg.rf.209e98415d463665863010946d22983e.jpg'\n",
      "b'Flower Dataset\\\\daisy\\\\10172567486_2748826a8b_jpg.rf.b5a2975b3a809e5e38693fa863fc4e8c.jpg'\n",
      "b'Flower Dataset\\\\daisy\\\\10172636503_21bededa75_n_jpg.rf.f76895eb82e0b112474335250a68378c.jpg'\n"
     ]
    }
   ],
   "source": [
    "for img in (list(image_ds.take(5).as_numpy_iterator())):\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['daisy', 'dandelion']\n",
    "img_count = len(image_ds)\n",
    "img_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(ds , train_size):\n",
    "    count = len(ds)\n",
    "    \n",
    "    train_size = int(count * train_size)\n",
    "    train_ds = ds.take(train_size) \n",
    "    test_ds = ds.skip(train_size) \n",
    "    \n",
    "    len(train_ds) , len(test_ds)\n",
    "    return train_ds ,test_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_label(img_path):\n",
    "    return tf.strings.split(img_path , os.path.sep)[-2]\n",
    "    \n",
    "def get_process_img(img_path):\n",
    "    label = get_label(img_path)\n",
    "    \n",
    "    img= tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128,128])\n",
    "    \n",
    "    return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor(\n",
      "[[[136.   137.   131.  ]\n",
      "  [144.5  145.5  140.5 ]\n",
      "  [147.5  147.5  145.5 ]\n",
      "  ...\n",
      "  [151.25 152.25 147.25]\n",
      "  [153.   154.   149.  ]\n",
      "  [151.5  152.5  147.5 ]]\n",
      "\n",
      " [[134.5  135.5  129.5 ]\n",
      "  [143.5  144.5  139.5 ]\n",
      "  [146.   146.   144.  ]\n",
      "  ...\n",
      "  [153.   154.   149.  ]\n",
      "  [152.5  153.5  148.5 ]\n",
      "  [148.75 149.75 144.75]]\n",
      "\n",
      " [[132.25 133.25 127.25]\n",
      "  [141.   142.   137.  ]\n",
      "  [144.5  144.5  142.5 ]\n",
      "  ...\n",
      "  [155.   156.   151.  ]\n",
      "  [150.75 151.75 146.75]\n",
      "  [147.   148.   143.  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 42.    46.    23.  ]\n",
      "  [ 42.    46.    23.  ]\n",
      "  [ 43.75  47.75  24.75]\n",
      "  ...\n",
      "  [128.75 124.75 121.75]\n",
      "  [127.   123.   120.  ]\n",
      "  [129.75 125.75 122.75]]\n",
      "\n",
      " [[ 44.    48.    25.  ]\n",
      "  [ 44.    48.    25.  ]\n",
      "  [ 44.    48.    25.  ]\n",
      "  ...\n",
      "  [131.   127.   124.  ]\n",
      "  [129.   125.   122.  ]\n",
      "  [129.   125.   122.  ]]\n",
      "\n",
      " [[ 44.    48.    25.  ]\n",
      "  [ 44.    48.    25.  ]\n",
      "  [ 44.    48.    25.  ]\n",
      "  ...\n",
      "  [132.75 128.75 125.75]\n",
      "  [130.   126.   123.  ]\n",
      "  [130.   126.   123.  ]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor(\n",
      "[[[212.25 217.25 223.25]\n",
      "  [207.5  212.5  218.5 ]\n",
      "  [213.75 218.75 224.75]\n",
      "  ...\n",
      "  [  9.25  13.25  12.25]\n",
      "  [  7.75  11.75  13.75]\n",
      "  [  4.75   8.75  11.75]]\n",
      "\n",
      " [[212.75 217.75 223.75]\n",
      "  [221.5  226.5  232.5 ]\n",
      "  [213.25 218.25 224.25]\n",
      "  ...\n",
      "  [  9.    13.    12.  ]\n",
      "  [  6.25  10.25  12.25]\n",
      "  [  3.5    7.5   10.5 ]]\n",
      "\n",
      " [[225.   230.   236.  ]\n",
      "  [223.75 228.75 234.75]\n",
      "  [217.75 222.75 228.75]\n",
      "  ...\n",
      "  [  9.75  13.75  12.75]\n",
      "  [  3.75   7.75   9.75]\n",
      "  [  0.75   4.75   7.75]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[172.25 173.25 177.75]\n",
      "  [176.5  177.5  182.  ]\n",
      "  [185.25 186.25 190.75]\n",
      "  ...\n",
      "  [148.25 143.25 123.75]\n",
      "  [170.75 164.75 150.75]\n",
      "  [180.   172.5  168.  ]]\n",
      "\n",
      " [[202.25 205.25 211.25]\n",
      "  [212.25 215.25 221.25]\n",
      "  [219.5  222.5  228.5 ]\n",
      "  ...\n",
      "  [149.   144.   123.  ]\n",
      "  [171.75 166.25 148.75]\n",
      "  [179.25 172.25 165.25]]\n",
      "\n",
      " [[226.   231.   237.  ]\n",
      "  [224.5  229.5  235.5 ]\n",
      "  [227.75 232.75 238.75]\n",
      "  ...\n",
      "  [150.25 145.5  122.75]\n",
      "  [173.5  168.   150.  ]\n",
      "  [175.25 168.25 159.25]]], shape=(128, 128, 3), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor(\n",
      "[[[127.75 130.5  113.75]\n",
      "  [121.5  122.   110.  ]\n",
      "  [106.5  103.5   96.5 ]\n",
      "  ...\n",
      "  [155.25 164.25 140.25]\n",
      "  [163.   172.25 146.5 ]\n",
      "  [142.25 158.   127.75]]\n",
      "\n",
      " [[121.   121.5  112.25]\n",
      "  [104.5  101.75  97.  ]\n",
      "  [ 89.75  84.25  85.  ]\n",
      "  ...\n",
      "  [135.   142.75 126.25]\n",
      "  [139.5  147.75 128.  ]\n",
      "  [125.   139.5  116.5 ]]\n",
      "\n",
      " [[107.   102.5  105.  ]\n",
      "  [ 90.5   84.25  90.  ]\n",
      "  [ 70.75  60.    72.  ]\n",
      "  ...\n",
      "  [118.75 125.75 111.75]\n",
      "  [119.75 127.75 111.25]\n",
      "  [112.5  126.5  106.5 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 26.    11.    40.  ]\n",
      "  [ 26.25  11.25  40.25]\n",
      "  [ 24.     9.    38.  ]\n",
      "  ...\n",
      "  [ 47.5   22.5   80.5 ]\n",
      "  [ 45.5   20.5   78.5 ]\n",
      "  [ 45.5   20.5   78.5 ]]\n",
      "\n",
      " [[ 26.    11.    40.  ]\n",
      "  [ 26.    11.    40.  ]\n",
      "  [ 23.5    8.5   37.5 ]\n",
      "  ...\n",
      "  [ 50.    22.    81.  ]\n",
      "  [ 52.    24.    83.  ]\n",
      "  [ 52.25  24.25  83.25]]\n",
      "\n",
      " [[ 23.     8.    37.  ]\n",
      "  [ 23.     8.    37.  ]\n",
      "  [ 25.    10.    39.  ]\n",
      "  ...\n",
      "  [ 51.    21.    81.  ]\n",
      "  [ 53.    23.    83.  ]\n",
      "  [ 50.5   20.5   80.5 ]]], shape=(128, 128, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_ds1 =  train_ds.map(get_process_img)\n",
    "for img,label in train_ds1.take(3):\n",
    "    print(label , img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._MapDataset"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.53333336 0.5372549  0.5137255 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.83235294 0.8519608  0.8754902 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.5009804  0.5117647  0.44607842], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#scallig img \n",
    "def scale(img , label):\n",
    "    img = img/255\n",
    "    return img , label\n",
    "\n",
    "train_ds2 =  train_ds1.map(scale)\n",
    "\n",
    "for img,label in train_ds2.take(3):\n",
    "    print(label , img[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in one single Line : Pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_3 = train_ds.map(get_process_img).map(scale).shuffle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.53333336 0.5372549  0.5137255 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.83235294 0.8519608  0.8754902 ], shape=(3,), dtype=float32)\n",
      "tf.Tensor(b'daisy', shape=(), dtype=string) tf.Tensor([0.5009804  0.5117647  0.44607842], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for img,label in train_ds_3.take(3):\n",
    "    print(label , img[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
